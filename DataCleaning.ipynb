{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5ea911-002f-487c-9c21-95da00705e6c",
   "metadata": {},
   "source": [
    "This dataset provides a comprehensive list of data science job postings sourced from Indeed. It includes details about job titles, companies, locations, salary ranges, short descriptions, and job links. The dataset is designed to help job seekers and researchers analyze current trends in the data science job market, understand salary expectations, and identify key hiring companies and locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34b2e0d-303b-425e-a45a-4ddf0b787a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaacc106-1597-4176-ad13-bed0a1ce3026",
   "metadata": {},
   "source": [
    "Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e6ed28-2dec-4568-85b2-b146d5ee39ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Load data from a CSV file\n",
    "df = pd.read_csv('../../Indeed-Data Science Jobs List 3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64062b-ca9b-43e6-8556-dfaf16523267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first five rows of the Dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674d949-6584-40db-a7f9-266c2dfcd5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the Position column since it was an index or a placeholder \n",
    "df = df.drop(columns=['Position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e476db5-e480-4424-b815-19f4db43f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the full URLs in the job link column, by adjusting the display option in pandas\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df.head()) #Displaying the result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaaef02-2faa-4bf0-a475-84ab93d20338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a concise summary of the DataFrame\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f2d28-b4a9-4d70-b452-0302e8e70b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Include categorical data:\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Numerical data only:\n",
    "print(df.describe(include=[np.number]))\n",
    "\n",
    "#Categorical data only:\n",
    "print(df.describe(include=[object]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df3d176-39ea-435a-8672-01d71da0be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking missing values\n",
    "\n",
    "print(df.isnull().sum())#Count the number of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf8e90-7f7d-437f-937d-367417836f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking unique values in a column\n",
    "\n",
    "print(df['Job Title'].unique())#Display unique values in a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c2220-bb0c-4272-a685-a5f7032ebab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Value counts\n",
    "\n",
    "print(df['Job Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1d4357-b819-448c-869c-e06396b58592",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa192633-d265-480d-b1f2-6740b2f37103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position               0\n",
      "Job Title              0\n",
      "Company                0\n",
      "Location               0\n",
      "Salary               138\n",
      "Short Description      0\n",
      "Posted At            184\n",
      "Job link               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Handling Missing Values\n",
    "#First Identifying missing values by printinng the number of missing values in each column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41421494-28b7-4c31-b85d-24579133c6b8",
   "metadata": {},
   "source": [
    "Handling Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90554731-86f0-4a2e-aaa7-2cfb7d2d85d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing rows or column that has missing data\n",
    "#Drop rows with any missing values\n",
    "df_clean = df.dropna()\n",
    "\n",
    "#Drop columns with any missing values\n",
    "df_clean = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c0c03d-4dbd-4ee2-8559-8d895f97c8fa",
   "metadata": {},
   "source": [
    "Impute Missing Values; \n",
    "\n",
    "- replace missing values with the mean, median or mode for numerical columns\n",
    "  \n",
    "- use the mode or a specific values for categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b20b7a-f883-4f29-9112-fa64fec78a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "#First, checking the column type for the column that has missing values\n",
    "print(df['Salary'].dtype)\n",
    "print(df['Posted At'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d977879d-6812-4ea2-9e74-dcd38d8387bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    120000.0\n",
      "1         NaN\n",
      "2         NaN\n",
      "3         NaN\n",
      "4    103409.0\n",
      "Name: Salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Because both the column type is object meant that the column contains strings or mixed types \n",
    "#Converting 'Salary' column to Numeric\n",
    "# Clean the \"Salary\" column by removing non-numeric characters and converting to numeric\n",
    "df['Salary'] = df['Salary'].str.replace(r'[\\$,]', '', regex=True).str.extract(r'(\\d+)').astype(float)\n",
    "print(df['Salary'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c988f3d-a9f6-4427-b323-8ae8284af883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values (NaN) with the mean\n",
    "# ensuring the original DataFrame is being modified by assigning the 'fillna' back to 'df['Salary']'\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].mean()) \n",
    "\n",
    "# For categorical data, fill missing values with the most frequent value (mode)\n",
    "# Ensuring the 'Posted At' column is directly modified in the original data frame\n",
    "df['Posted At'] = df['Posted At'].fillna(df['Posted At'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb2335c2-f886-4a96-9c48-25600ece79b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 'Salary' column:\n",
      "0    120000.000000\n",
      "1    111460.532258\n",
      "2    111460.532258\n",
      "3    111460.532258\n",
      "4    103409.000000\n",
      "Name: Salary, dtype: float64\n",
      "Updated 'Posted At' column:\n",
      "0    Employer\\nActive 3 days ago\n",
      "1    Employer\\nActive 3 days ago\n",
      "2    Employer\\nActive 3 days ago\n",
      "3    Employer\\nActive 3 days ago\n",
      "4    Employer\\nActive 3 days ago\n",
      "Name: Posted At, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the first few rows of the 'Salary' column to see the changes\n",
    "print(\"Updated 'Salary' column:\")\n",
    "print(df['Salary'].head())\n",
    "\n",
    "# Print the first few rows of the 'Posted At' column to see the changes\n",
    "print(\"Updated 'Posted At' column:\")\n",
    "print(df['Posted At'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e0d8a-c731-498d-bcef-14abb6c2437d",
   "metadata": {},
   "source": [
    "- The Salary column now holds numeric data as expected, and it seems to have worked correctly by filling the missing values with the column mean.\n",
    "- The Posted At column has been filled with the most frequent entry, which seems to be the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc897a76-e47f-4c11-98e8-2f7d4b5fb3c0",
   "metadata": {},
   "source": [
    "This last final part is to check for further details and checking any other 'NaN' values using 'df.isna90.sum()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cff8754-ed80-4434-81b5-b6c1646d0764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining NaN values in each column:\n",
      "Position             0\n",
      "Job Title            0\n",
      "Company              0\n",
      "Location             0\n",
      "Salary               0\n",
      "Short Description    0\n",
      "Posted At            0\n",
      "Job link             0\n",
      "dtype: int64\n",
      "First 10 rows of the DataFrame:\n",
      "   Position                                          Job Title  \\\n",
      "0         1                                     Data Scientist   \n",
      "1         2  Senior Artificial Intelligence Researcher for ...   \n",
      "2         3                              Senior Data Scientist   \n",
      "3         4                                     Data Scientist   \n",
      "4         5                                     Data Scientist   \n",
      "5         6                                     Data Scientist   \n",
      "6         7                   Business Data Scientist/Engineer   \n",
      "7         8                                   Data Scientist I   \n",
      "8         9                                     Data Scientist   \n",
      "9        10                           Associate Data Scientist   \n",
      "\n",
      "                                          Company  \\\n",
      "0                                     Robert Half   \n",
      "1  Johns Hopkins Applied Physics Laboratory (APL)   \n",
      "2               Modern Technology Solutions, Inc.   \n",
      "3                        Twitch Interactive, Inc.   \n",
      "4               US Office of Personnel Management   \n",
      "5                                  MagicSchool AI   \n",
      "6                                           Apple   \n",
      "7                                    GM Financial   \n",
      "8                                Ropes & Gray LLP   \n",
      "9                                            UPMC   \n",
      "\n",
      "                              Location         Salary  \\\n",
      "0      Remote in Los Angeles, CA 90024  120000.000000   \n",
      "1                     Laurel, MD 20723  111460.532258   \n",
      "2                 Huntsville, AL 35895  111460.532258   \n",
      "3                          Seattle, WA  111460.532258   \n",
      "4                               Remote  103409.000000   \n",
      "5                   Remote in Colorado  111460.532258   \n",
      "6                           Austin, TX  111460.532258   \n",
      "7        Hybrid work in Fort Worth, TX  111460.532258   \n",
      "8      Hybrid work in Boston, MA 02199  125000.000000   \n",
      "9  Pittsburgh, PA 15219 \\n(Bluff area)  111460.532258   \n",
      "\n",
      "                                   Short Description  \\\n",
      "0  The ideal candidate should be highly skilled i...   \n",
      "1  As a member of our research team, you will con...   \n",
      "2  Utilize machine learning techniques, algorithm...   \n",
      "3  Conduct ad-hoc analyses, build robust automate...   \n",
      "4  Develops and maintains analytics product proje...   \n",
      "5  Enable smarter business processes by utilizing...   \n",
      "6  You will work closely with multi-functional te...   \n",
      "7  The Data Scientist I is the subject matter exp...   \n",
      "8  You will work with lawyers, behavioral scienti...   \n",
      "9  Design, develop, and implement health care ana...   \n",
      "\n",
      "                     Posted At  \\\n",
      "0  Employer\\nActive 3 days ago   \n",
      "1  Employer\\nActive 3 days ago   \n",
      "2  Employer\\nActive 3 days ago   \n",
      "3  Employer\\nActive 3 days ago   \n",
      "4  Employer\\nActive 3 days ago   \n",
      "5  Employer\\nActive 3 days ago   \n",
      "6  Employer\\nActive 3 days ago   \n",
      "7  Employer\\nActive 3 days ago   \n",
      "8  Employer\\nActive 3 days ago   \n",
      "9  Employer\\nActive 3 days ago   \n",
      "\n",
      "                                            Job link  \n",
      "0  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
      "1  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
      "2  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
      "3  https://www.indeed.com/rc/clk?jk=4593a41913786...  \n",
      "4  https://www.indeed.com/rc/clk?jk=d393197b7bc42...  \n",
      "5  https://www.indeed.com/rc/clk?jk=258a205f5e303...  \n",
      "6  https://www.indeed.com/rc/clk?jk=563bac05a8878...  \n",
      "7  https://www.indeed.com/rc/clk?jk=85b9540e6b08e...  \n",
      "8  https://www.indeed.com/rc/clk?jk=fec3590ced9d6...  \n",
      "9  https://www.indeed.com/rc/clk?jk=f5de21340edf2...  \n",
      "Last 10 rows of the DataFrame:\n",
      "     Position                                 Job Title  \\\n",
      "190       191                 Distinguished AI Engineer   \n",
      "191       192                            Data Scientist   \n",
      "192       193  Data Scientist for Enrollment Management   \n",
      "193       194              Data Scientist - Credit Risk   \n",
      "194       195                     Senior Data Scientist   \n",
      "195       196               Sr. Manager, Data Scientist   \n",
      "196       197          Senior Data Scientist (New York)   \n",
      "197       198                   Contract Data Scientist   \n",
      "198       199             Statistical Programmer ONSITE   \n",
      "199       200                            Data Scientist   \n",
      "\n",
      "                                Company  \\\n",
      "190                   Acadia Healthcare   \n",
      "191         SRS Distribution - McKinney   \n",
      "192  California Institute of Technology   \n",
      "193                     Associated Bank   \n",
      "194                         Xilis, Inc.   \n",
      "195                            McKesson   \n",
      "196                    The Voleon Group   \n",
      "197                Sarepta Therapeutics   \n",
      "198             Maxis Clinical Sciences   \n",
      "199                          Booz Allen   \n",
      "\n",
      "                                     Location         Salary  \\\n",
      "190        Franklin, TN 37067 \\n(McEwen area)  111460.532258   \n",
      "191                        McKinney, TX 75070   84700.000000   \n",
      "192      Pasadena, CA 91125 \\n(Pasadena area)  111460.532258   \n",
      "193                                 Wisconsin  111460.532258   \n",
      "194                                Durham, NC  111460.532258   \n",
      "195                Remote in Irving, TX 75039  111460.532258   \n",
      "196               Hybrid work in New York, NY  111460.532258   \n",
      "197                   Remote in Cambridge, MA  111460.532258   \n",
      "198  Jacksonville, FL 32256 \\n(Deerwood area)  105000.000000   \n",
      "199                             Arlington, VA   96600.000000   \n",
      "\n",
      "                                     Short Description  \\\n",
      "190  Deep understanding of data structures, algorit...   \n",
      "191  Drive novel insights from large and complex da...   \n",
      "192  Design and conduct complex data analyses using...   \n",
      "193  Retirement savings including both 401(k) and P...   \n",
      "194  You will help lead the design and implementati...   \n",
      "195  Demonstrated ability to tackle problems across...   \n",
      "196  This policy is part of Voleon’s ongoing effort...   \n",
      "197  Ability to effectively communicate and work wi...   \n",
      "198  Provide statistical programming support for cl...   \n",
      "199  We are a cross-functional team of data scienti...   \n",
      "\n",
      "                       Posted At  \\\n",
      "190  Employer\\nActive 3 days ago   \n",
      "191  Employer\\nActive 3 days ago   \n",
      "192  Employer\\nActive 3 days ago   \n",
      "193  Employer\\nActive 3 days ago   \n",
      "194  Employer\\nActive 3 days ago   \n",
      "195  Employer\\nActive 3 days ago   \n",
      "196  Employer\\nActive 3 days ago   \n",
      "197  Employer\\nActive 3 days ago   \n",
      "198  Employer\\nActive 3 days ago   \n",
      "199  Employer\\nActive 3 days ago   \n",
      "\n",
      "                                              Job link  \n",
      "190  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...  \n",
      "191  https://www.indeed.com/rc/clk?jk=f77e0aa534aab...  \n",
      "192  https://www.indeed.com/rc/clk?jk=d623d7bfa7c8a...  \n",
      "193  https://www.indeed.com/rc/clk?jk=10657d1693bae...  \n",
      "194  https://www.indeed.com/rc/clk?jk=b6f9af7e6f3c2...  \n",
      "195  https://www.indeed.com/rc/clk?jk=8444134138126...  \n",
      "196  https://www.indeed.com/rc/clk?jk=a76b33c6fed55...  \n",
      "197  https://www.indeed.com/rc/clk?jk=21ed00a315415...  \n",
      "198  https://www.indeed.com/rc/clk?jk=4a01247d47986...  \n",
      "199  https://www.indeed.com/rc/clk?jk=e9d6f6da84277...  \n"
     ]
    }
   ],
   "source": [
    "# Check for remaining NaN values in the DataFrame\n",
    "print(\"Remaining NaN values in each column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Inspect the first 10 rows of the DataFrame\n",
    "print(\"First 10 rows of the DataFrame:\")\n",
    "print(df.head(10))\n",
    "\n",
    "# Inspect the last 10 rows of the DataFrame\n",
    "print(\"Last 10 rows of the DataFrame:\")\n",
    "print(df.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2f2a4c7-8acb-44df-8f48-8340a0241985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = '../../Indeed-Data Science Jobs List 3.csv'\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    print(\"File has been saved successfully!\")\n",
    "else:\n",
    "    print(\"File does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e7d1a-976a-4702-91fd-6cd3ab0a9e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
